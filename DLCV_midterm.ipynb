{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CITATIONS:\n",
    "- https://github.com/poojahira/gtsrb-pytorch\n",
    "- https://github.com/surajmurthy/TSR_PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nclasses):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250*2*2, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 4 * 4, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = x.view(-1, 250*2*2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "class FMnet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes,\n",
    "        img_ch=1,\n",
    "        channels=[16, 32, 64, 128, 200],\n",
    "        device=['cuda' if torch.cuda.is_available() else 'cpu'][0],\n",
    "        kernel=3,\n",
    "        shape=(256, 256),\n",
    "        n_upsample=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_upsample = n_upsample\n",
    "        self.image_shape = shape\n",
    "        self.device = device\n",
    "        self.channels = channels\n",
    "\n",
    "        self.Conv = nn.Sequential()\n",
    "        self.Conv.add_module(\n",
    "            \"conv0\",\n",
    "            convblock(ch_in=img_ch, ch_out=channels[0], kernel_sz=kernel, block=0),\n",
    "        )\n",
    "        for k in range(1, len(channels)):\n",
    "            self.Conv.add_module(\n",
    "                f\"conv{k}\",\n",
    "                convblock(\n",
    "                    ch_in=channels[k - 1], ch_out=channels[k], kernel_sz=kernel, block=k\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(self.channels[-1]*14*16, 350)\n",
    "        self.fc2 = nn.Linear(350, n_classes)\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 4 * 4, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def forward(self, x, normalize=False, verbose=False):\n",
    "        # encoding path\n",
    "        xout = []\n",
    "        x = self.Conv[0](x)\n",
    "        xout.append(x)\n",
    "        for k in range(1, len(self.Conv)):\n",
    "            x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "            x = self.Conv[k](x)\n",
    "            xout.append(x)\n",
    "\n",
    "        # transform the input\n",
    "        x = self.conv_drop(x)\n",
    "        x = x.view(-1, self.channels[-1]*14*16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "class convblock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_sz, block=-1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.block = block\n",
    "        if self.block != 0:\n",
    "            self.conv.add_module(\"conv_0\", batchconv(ch_in, ch_out, kernel_sz))\n",
    "        else:\n",
    "            self.conv.add_module(\"conv_0\", batchconv0(ch_in, ch_out, kernel_sz))\n",
    "        self.conv.add_module(\"conv_1\", batchconv(ch_out, ch_out, kernel_sz))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv[1](self.conv[0](x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def batchconv0(ch_in, ch_out, kernel_sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.Conv2d(ch_in, ch_out, kernel_sz, padding=kernel_sz // 2, bias=False),\n",
    "    )\n",
    "\n",
    "\n",
    "def batchconv(ch_in, ch_out, sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(ch_in, ch_out, sz, padding=sz // 2, bias=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path of training data\n",
    "transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize([212, 256]),\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Resize((32, 32)),\n",
    "    #transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "train_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images' \n",
    "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform=transform)\n",
    "\n",
    "# Divide data into training and validation \n",
    "ratio = 0.9\n",
    "n_train_examples = int(len(train_data) * ratio)\n",
    "n_val_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
    "print(f\"Number of training samples = {len(train_data)}\")\n",
    "print(f\"Number of validation samples = {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_classes = len(train_data.dataset.classes)\n",
    "train_hist = [0]*num_train_classes\n",
    "for i in train_data.indices:\n",
    "    tar = train_data.dataset.targets[i]\n",
    "    train_hist[tar] += 1\n",
    "\n",
    "num_val_classes = len(val_data.dataset.classes)\n",
    "val_hist = [0]*num_val_classes\n",
    "for i in val_data.indices:\n",
    "    tar = val_data.dataset.targets[i]\n",
    "    val_hist[tar] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(num_train_classes), train_hist, label=\"train\")\n",
    "plt.bar(range(num_val_classes), val_hist, label=\"val\")\n",
    "#plt.bar(range(num_test_classes), test_hist, label=\"test\")\n",
    "legend = plt.legend(loc='upper right', shadow=True)\n",
    "plt.title(\"Distribution Plot\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"# of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for training and validation\n",
    "BATCH_SIZE = 100\n",
    "LOG_INTERVAL = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_loader = data.DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network and Optimizer\n",
    "model = FMnet(num_train_classes) #Net(nclasses=43)#FMnet(num_train_classes)\n",
    "model = model.to(device);\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % 2 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(BATCH_SIZE * LOG_INTERVAL),loss.data.item()))\n",
    "    print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = 'trained_models/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('\\nSaved model to ' + model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e019fd396ec95f049220eceb1ef17507a867cb3a5a0d714b39db56f962322af5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
