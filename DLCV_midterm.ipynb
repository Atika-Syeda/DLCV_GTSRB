{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CITATIONS:\n",
    "- https://github.com/poojahira/gtsrb-pytorch\n",
    "- https://github.com/surajmurthy/TSR_PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision.io import read_image\n",
    "from model import GTSRBnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 35288\n",
      "Number of validation samples = 3921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# of examples')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize([212, 256]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define path of training data\n",
    "train_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images' \n",
    "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform=transform)\n",
    "\n",
    "# Divide data into training and validation set\n",
    "train_ratio = 0.9\n",
    "n_train_examples = int(len(train_data) * train_ratio)\n",
    "n_val_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
    "print(f\"Number of training samples = {len(train_data)}\")\n",
    "print(f\"Number of validation samples = {len(val_data)}\")\n",
    "\n",
    "num_train_classes = len(train_data.dataset.classes)\n",
    "train_hist = [0]*num_train_classes\n",
    "for i in train_data.indices:\n",
    "    tar = train_data.dataset.targets[i]\n",
    "    train_hist[tar] += 1\n",
    "\n",
    "num_val_classes = len(val_data.dataset.classes)\n",
    "val_hist = [0]*num_val_classes\n",
    "for i in val_data.indices:\n",
    "    tar = val_data.dataset.targets[i]\n",
    "    val_hist[tar] += 1\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(num_train_classes), train_hist, label=\"train\")\n",
    "plt.bar(range(num_val_classes), val_hist, label=\"val\")\n",
    "#plt.bar(range(num_test_classes), test_hist, label=\"test\")\n",
    "legend = plt.legend(loc='upper right', shadow=True)\n",
    "plt.title(\"Distribution Plot\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"# of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for training and validation\n",
    "BATCH_SIZE = 100\n",
    "LOG_INTERVAL = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = data.DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_loader = data.DataLoader(val_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Neural Network and Optimizer\n",
    "model = GTSRBnet(num_train_classes)\n",
    "model = model.to(device);\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(BATCH_SIZE * LOG_INTERVAL),loss.data.item()))\n",
    "    avg_train_loss = training_loss / len(train_loader.dataset)\n",
    "    avg_train_acc = 100. * correct / len(train_loader.dataset)\n",
    "    print('\\nTraining set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "                avg_train_loss, avg_train_acc))\n",
    "    return avg_train_loss, avg_train_acc\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    validation_acc = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {:.0f}%\\n'.format(\n",
    "        validation_loss, validation_acc))\n",
    "    return validation_loss, validation_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35288 (0%)]\tLoss per example: 0.000377\tLoss: 3.771584\n",
      "Train Epoch: 1 [1000/35288 (3%)]\tLoss per example: 0.000380\tLoss: 3.798339\n",
      "Train Epoch: 1 [2000/35288 (6%)]\tLoss per example: 0.000417\tLoss: 4.168219\n",
      "Train Epoch: 1 [3000/35288 (8%)]\tLoss per example: 0.000377\tLoss: 3.771859\n",
      "Train Epoch: 1 [4000/35288 (11%)]\tLoss per example: 0.000371\tLoss: 3.710956\n",
      "Train Epoch: 1 [5000/35288 (14%)]\tLoss per example: 0.000363\tLoss: 3.630858\n",
      "Train Epoch: 1 [6000/35288 (17%)]\tLoss per example: 0.000361\tLoss: 3.606360\n",
      "Train Epoch: 1 [7000/35288 (20%)]\tLoss per example: 0.000372\tLoss: 3.716578\n",
      "Train Epoch: 1 [8000/35288 (23%)]\tLoss per example: 0.000365\tLoss: 3.646364\n",
      "Train Epoch: 1 [9000/35288 (25%)]\tLoss per example: 0.000358\tLoss: 3.578210\n",
      "Train Epoch: 1 [10000/35288 (28%)]\tLoss per example: 0.000363\tLoss: 3.630767\n",
      "Train Epoch: 1 [11000/35288 (31%)]\tLoss per example: 0.000364\tLoss: 3.643912\n",
      "Train Epoch: 1 [12000/35288 (34%)]\tLoss per example: 0.000353\tLoss: 3.528560\n",
      "Train Epoch: 1 [13000/35288 (37%)]\tLoss per example: 0.000355\tLoss: 3.549981\n",
      "Train Epoch: 1 [14000/35288 (40%)]\tLoss per example: 0.000359\tLoss: 3.594165\n",
      "Train Epoch: 1 [15000/35288 (42%)]\tLoss per example: 0.000347\tLoss: 3.474169\n",
      "Train Epoch: 1 [16000/35288 (45%)]\tLoss per example: 0.000346\tLoss: 3.459906\n",
      "Train Epoch: 1 [17000/35288 (48%)]\tLoss per example: 0.000331\tLoss: 3.312824\n",
      "Train Epoch: 1 [18000/35288 (51%)]\tLoss per example: 0.000345\tLoss: 3.454871\n",
      "Train Epoch: 1 [19000/35288 (54%)]\tLoss per example: 0.000338\tLoss: 3.378551\n",
      "Train Epoch: 1 [20000/35288 (57%)]\tLoss per example: 0.000302\tLoss: 3.023063\n",
      "Train Epoch: 1 [21000/35288 (59%)]\tLoss per example: 0.000317\tLoss: 3.172087\n",
      "Train Epoch: 1 [22000/35288 (62%)]\tLoss per example: 0.000291\tLoss: 2.914212\n",
      "Train Epoch: 1 [23000/35288 (65%)]\tLoss per example: 0.000265\tLoss: 2.654016\n",
      "Train Epoch: 1 [24000/35288 (68%)]\tLoss per example: 0.000272\tLoss: 2.716522\n",
      "Train Epoch: 1 [25000/35288 (71%)]\tLoss per example: 0.000277\tLoss: 2.769563\n",
      "Train Epoch: 1 [26000/35288 (74%)]\tLoss per example: 0.000244\tLoss: 2.435412\n",
      "Train Epoch: 1 [27000/35288 (76%)]\tLoss per example: 0.000251\tLoss: 2.510629\n",
      "Train Epoch: 1 [28000/35288 (79%)]\tLoss per example: 0.000247\tLoss: 2.472976\n",
      "Train Epoch: 1 [29000/35288 (82%)]\tLoss per example: 0.000198\tLoss: 1.975572\n",
      "Train Epoch: 1 [30000/35288 (85%)]\tLoss per example: 0.000211\tLoss: 2.110952\n",
      "Train Epoch: 1 [31000/35288 (88%)]\tLoss per example: 0.000215\tLoss: 2.149134\n",
      "Train Epoch: 1 [32000/35288 (91%)]\tLoss per example: 0.000251\tLoss: 2.508797\n",
      "Train Epoch: 1 [33000/35288 (93%)]\tLoss per example: 0.000200\tLoss: 1.995336\n",
      "Train Epoch: 1 [34000/35288 (96%)]\tLoss per example: 0.000179\tLoss: 1.788542\n",
      "Train Epoch: 1 [35000/35288 (99%)]\tLoss per example: 0.000189\tLoss: 1.885270\n",
      "\n",
      "Training set: Average loss: 0.0312, Accuracy: (16%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stringlab/anaconda3/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 1.6341, Accuracy: 50%\n",
      "\n",
      "\n",
      "Saved model to trained_models/model_1.pth\n",
      "Train Epoch: 2 [0/35288 (0%)]\tLoss per example: 0.000199\tLoss: 1.993444\n",
      "Train Epoch: 2 [1000/35288 (3%)]\tLoss per example: 0.000223\tLoss: 2.231097\n",
      "Train Epoch: 2 [2000/35288 (6%)]\tLoss per example: 0.000169\tLoss: 1.693544\n",
      "Train Epoch: 2 [3000/35288 (8%)]\tLoss per example: 0.000174\tLoss: 1.736700\n",
      "Train Epoch: 2 [4000/35288 (11%)]\tLoss per example: 0.000186\tLoss: 1.862376\n",
      "Train Epoch: 2 [5000/35288 (14%)]\tLoss per example: 0.000132\tLoss: 1.322963\n",
      "Train Epoch: 2 [6000/35288 (17%)]\tLoss per example: 0.000129\tLoss: 1.290545\n",
      "Train Epoch: 2 [7000/35288 (20%)]\tLoss per example: 0.000173\tLoss: 1.734731\n",
      "Train Epoch: 2 [8000/35288 (23%)]\tLoss per example: 0.000132\tLoss: 1.315735\n",
      "Train Epoch: 2 [9000/35288 (25%)]\tLoss per example: 0.000142\tLoss: 1.424139\n",
      "Train Epoch: 2 [10000/35288 (28%)]\tLoss per example: 0.000149\tLoss: 1.488037\n",
      "Train Epoch: 2 [11000/35288 (31%)]\tLoss per example: 0.000110\tLoss: 1.104162\n",
      "Train Epoch: 2 [12000/35288 (34%)]\tLoss per example: 0.000111\tLoss: 1.111719\n",
      "Train Epoch: 2 [13000/35288 (37%)]\tLoss per example: 0.000134\tLoss: 1.341855\n",
      "Train Epoch: 2 [14000/35288 (40%)]\tLoss per example: 0.000082\tLoss: 0.821731\n",
      "Train Epoch: 2 [15000/35288 (42%)]\tLoss per example: 0.000077\tLoss: 0.767366\n",
      "Train Epoch: 2 [16000/35288 (45%)]\tLoss per example: 0.000108\tLoss: 1.083332\n",
      "Train Epoch: 2 [17000/35288 (48%)]\tLoss per example: 0.000072\tLoss: 0.723166\n",
      "Train Epoch: 2 [18000/35288 (51%)]\tLoss per example: 0.000062\tLoss: 0.621282\n",
      "Train Epoch: 2 [19000/35288 (54%)]\tLoss per example: 0.000078\tLoss: 0.775088\n",
      "Train Epoch: 2 [20000/35288 (57%)]\tLoss per example: 0.000073\tLoss: 0.734502\n",
      "Train Epoch: 2 [21000/35288 (59%)]\tLoss per example: 0.000052\tLoss: 0.517923\n",
      "Train Epoch: 2 [22000/35288 (62%)]\tLoss per example: 0.000061\tLoss: 0.611061\n",
      "Train Epoch: 2 [23000/35288 (65%)]\tLoss per example: 0.000068\tLoss: 0.676351\n",
      "Train Epoch: 2 [24000/35288 (68%)]\tLoss per example: 0.000060\tLoss: 0.596097\n",
      "Train Epoch: 2 [25000/35288 (71%)]\tLoss per example: 0.000056\tLoss: 0.561759\n",
      "Train Epoch: 2 [26000/35288 (74%)]\tLoss per example: 0.000041\tLoss: 0.410898\n",
      "Train Epoch: 2 [27000/35288 (76%)]\tLoss per example: 0.000039\tLoss: 0.394582\n",
      "Train Epoch: 2 [28000/35288 (79%)]\tLoss per example: 0.000040\tLoss: 0.400081\n",
      "Train Epoch: 2 [29000/35288 (82%)]\tLoss per example: 0.000037\tLoss: 0.365243\n",
      "Train Epoch: 2 [30000/35288 (85%)]\tLoss per example: 0.000032\tLoss: 0.323521\n",
      "Train Epoch: 2 [31000/35288 (88%)]\tLoss per example: 0.000037\tLoss: 0.370656\n",
      "Train Epoch: 2 [32000/35288 (91%)]\tLoss per example: 0.000029\tLoss: 0.294904\n",
      "Train Epoch: 2 [33000/35288 (93%)]\tLoss per example: 0.000031\tLoss: 0.311957\n",
      "Train Epoch: 2 [34000/35288 (96%)]\tLoss per example: 0.000023\tLoss: 0.232695\n",
      "Train Epoch: 2 [35000/35288 (99%)]\tLoss per example: 0.000050\tLoss: 0.497007\n",
      "\n",
      "Training set: Average loss: 0.0091, Accuracy: (73%)\n",
      "\n",
      "\n",
      "Validation set: Average loss: 0.1359, Accuracy: 96%\n",
      "\n",
      "\n",
      "Saved model to trained_models/model_2.pth\n",
      "Train Epoch: 3 [0/35288 (0%)]\tLoss per example: 0.000021\tLoss: 0.213311\n",
      "Train Epoch: 3 [1000/35288 (3%)]\tLoss per example: 0.000012\tLoss: 0.116573\n",
      "Train Epoch: 3 [2000/35288 (6%)]\tLoss per example: 0.000020\tLoss: 0.196131\n",
      "Train Epoch: 3 [3000/35288 (8%)]\tLoss per example: 0.000010\tLoss: 0.095095\n",
      "Train Epoch: 3 [4000/35288 (11%)]\tLoss per example: 0.000022\tLoss: 0.216599\n",
      "Train Epoch: 3 [5000/35288 (14%)]\tLoss per example: 0.000033\tLoss: 0.332191\n",
      "Train Epoch: 3 [6000/35288 (17%)]\tLoss per example: 0.000021\tLoss: 0.210183\n",
      "Train Epoch: 3 [7000/35288 (20%)]\tLoss per example: 0.000011\tLoss: 0.108415\n",
      "Train Epoch: 3 [8000/35288 (23%)]\tLoss per example: 0.000030\tLoss: 0.297619\n",
      "Train Epoch: 3 [9000/35288 (25%)]\tLoss per example: 0.000021\tLoss: 0.212965\n",
      "Train Epoch: 3 [10000/35288 (28%)]\tLoss per example: 0.000025\tLoss: 0.246558\n",
      "Train Epoch: 3 [11000/35288 (31%)]\tLoss per example: 0.000008\tLoss: 0.078858\n",
      "Train Epoch: 3 [12000/35288 (34%)]\tLoss per example: 0.000035\tLoss: 0.346473\n",
      "Train Epoch: 3 [13000/35288 (37%)]\tLoss per example: 0.000020\tLoss: 0.196097\n",
      "Train Epoch: 3 [14000/35288 (40%)]\tLoss per example: 0.000014\tLoss: 0.140776\n",
      "Train Epoch: 3 [15000/35288 (42%)]\tLoss per example: 0.000021\tLoss: 0.214831\n",
      "Train Epoch: 3 [16000/35288 (45%)]\tLoss per example: 0.000026\tLoss: 0.261531\n",
      "Train Epoch: 3 [17000/35288 (48%)]\tLoss per example: 0.000006\tLoss: 0.060317\n",
      "Train Epoch: 3 [18000/35288 (51%)]\tLoss per example: 0.000009\tLoss: 0.089023\n",
      "Train Epoch: 3 [19000/35288 (54%)]\tLoss per example: 0.000010\tLoss: 0.096100\n",
      "Train Epoch: 3 [20000/35288 (57%)]\tLoss per example: 0.000022\tLoss: 0.222177\n",
      "Train Epoch: 3 [21000/35288 (59%)]\tLoss per example: 0.000027\tLoss: 0.267294\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = [], []\n",
    "val_loss, val_acc = [], []\n",
    "for epoch in range(1, 50):\n",
    "    avg_train_loss, avg_train_acc = train(epoch)\n",
    "    avg_val_loss, avg_val_acc = validation()\n",
    "    train_loss.append(avg_train_loss)\n",
    "    train_acc.append(avg_train_acc)\n",
    "    val_loss.append(avg_val_loss)\n",
    "    val_acc.append(avg_val_acc)\n",
    "    model_file = 'trained_models/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('\\nSaved model to ' + model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].plot(train_loss, label='train')\n",
    "ax[0].plot(val_loss, label='val')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend()\n",
    "ax[1].plot(train_acc, label='train')\n",
    "ax[1].plot(val_acc, label='val')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e019fd396ec95f049220eceb1ef17507a867cb3a5a0d714b39db56f962322af5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
