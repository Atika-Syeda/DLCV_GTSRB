{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CITATIONS:\n",
    "- https://github.com/poojahira/gtsrb-pytorch\n",
    "- https://github.com/surajmurthy/TSR_PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nclasses):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250*2*2, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 4 * 4, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = x.view(-1, 250*2*2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "class FMnet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes,\n",
    "        img_ch=1,\n",
    "        channels=[16, 32, 64, 128, 200],\n",
    "        device=['cuda' if torch.cuda.is_available() else 'cpu'][0],\n",
    "        kernel=3,\n",
    "        shape=(256, 256),\n",
    "        n_upsample=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_upsample = n_upsample\n",
    "        self.image_shape = shape\n",
    "        self.device = device\n",
    "\n",
    "        self.Conv = nn.Sequential()\n",
    "        self.Conv.add_module(\n",
    "            \"conv0\",\n",
    "            convblock(ch_in=img_ch, ch_out=channels[0], kernel_sz=kernel, block=0),\n",
    "        )\n",
    "        for k in range(1, len(channels)):\n",
    "            self.Conv.add_module(\n",
    "                f\"conv{k}\",\n",
    "                convblock(\n",
    "                    ch_in=channels[k - 1], ch_out=channels[k], kernel_sz=kernel, block=k\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.Up_conv = nn.Sequential()\n",
    "        for k in range(n_upsample):\n",
    "            self.Up_conv.add_module(\n",
    "                f\"upconv{k}\",\n",
    "                convblock(\n",
    "                    ch_in=channels[-1 - k] + channels[-2 - k],\n",
    "                    ch_out=channels[-2 - k],\n",
    "                    kernel_sz=kernel,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.fc1 = nn.Linear(channels[-2 - k]*2*2, 350)\n",
    "        self.fc2 = nn.Linear(350, n_classes)\n",
    "\n",
    "    def forward(self, x, normalize=False, verbose=False):\n",
    "        # encoding path\n",
    "        xout = []\n",
    "        x = self.Conv[0](x)\n",
    "        xout.append(x)\n",
    "        for k in range(1, len(self.Conv)):\n",
    "            x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "            x = self.Conv[k](x)\n",
    "            xout.append(x)\n",
    "\n",
    "        for k in range(len(self.Up_conv)):\n",
    "            x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "            x = self.Up_conv[k](torch.cat((x, xout[-2 - k]), axis=1))\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "# Create a gaussian wavelet of a set bin size\n",
    "def gaussian_wavelet(bin_size, sigma):\n",
    "    x = np.arange(-bin_size // 2, bin_size // 2 + 1)\n",
    "    gaussian = np.exp(-(x ** 2) / (2 * sigma ** 2))\n",
    "    return gaussian / gaussian.sum()\n",
    "\n",
    "\n",
    "class convblock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_sz, block=-1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.block = block\n",
    "        if self.block != 0:\n",
    "            self.conv.add_module(\"conv_0\", batchconv(ch_in, ch_out, kernel_sz))\n",
    "        else:\n",
    "            self.conv.add_module(\"conv_0\", batchconv0(ch_in, ch_out, kernel_sz))\n",
    "        self.conv.add_module(\"conv_1\", batchconv(ch_out, ch_out, kernel_sz))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv[1](self.conv[0](x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def batchconv0(ch_in, ch_out, kernel_sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.Conv2d(ch_in, ch_out, kernel_sz, padding=kernel_sz // 2, bias=False),\n",
    "    )\n",
    "\n",
    "\n",
    "def batchconv(ch_in, ch_out, sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(ch_in, ch_out, sz, padding=sz // 2, bias=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix test data targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 35288\n",
      "Number of validation samples = 3921\n"
     ]
    }
   ],
   "source": [
    "# Define path of training data\n",
    "transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize([212, 256]),\n",
    "    transforms.ToTensor()\n",
    "    #transforms.Resize((32, 32)),\n",
    "    #transforms.ToTensor(),\n",
    "    #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "train_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images' \n",
    "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform=transform)\n",
    "\n",
    "test_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Test_Images/GTSRB'\n",
    "test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform=transform)\n",
    "\n",
    "# Divide data into training and validation \n",
    "ratio = 0.9\n",
    "n_train_examples = int(len(train_data) * ratio)\n",
    "n_val_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
    "print(f\"Number of training samples = {len(train_data)}\")\n",
    "print(f\"Number of validation samples = {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_classes = len(train_data.dataset.classes)\n",
    "train_hist = [0]*num_train_classes\n",
    "for i in train_data.indices:\n",
    "    tar = train_data.dataset.targets[i]\n",
    "    train_hist[tar] += 1\n",
    "\n",
    "num_val_classes = len(val_data.dataset.classes)\n",
    "val_hist = [0]*num_val_classes\n",
    "for i in val_data.indices:\n",
    "    tar = val_data.dataset.targets[i]\n",
    "    val_hist[tar] += 1\n",
    "\n",
    "num_test_classes = len(np.unique(test_data.targets))\n",
    "test_hist = [0]*num_test_classes\n",
    "for i, t in enumerate(test_data.targets):\n",
    "    test_hist[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# of examples')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(num_train_classes), train_hist, label=\"train\")\n",
    "plt.bar(range(num_val_classes), val_hist, label=\"val\")\n",
    "#plt.bar(range(num_test_classes), test_hist, label=\"test\")\n",
    "legend = plt.legend(loc='upper right', shadow=True)\n",
    "plt.title(\"Distribution Plot\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"# of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for training and validation\n",
    "BATCH_SIZE = 100\n",
    "LOG_INTERVAL = 100\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = data.DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "val_loader = data.DataLoader(val_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "test_loader = data.DataLoader(test_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "\n",
    "# Neural Network and Optimizer\n",
    "model = FMnet(num_train_classes)#Net()\n",
    "model = model.to(device);\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FMnet(\n",
       "  (Conv): Sequential(\n",
       "    (conv0): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv1): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv2): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv3): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (conv4): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (Up_conv): Sequential(\n",
       "    (upconv0): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(328, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upconv1): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upconv2): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (upconv3): convblock(\n",
       "      (conv): Sequential(\n",
       "        (conv_0): Sequential(\n",
       "          (0): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(48, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (conv_1): Sequential(\n",
       "          (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=64, out_features=350, bias=True)\n",
       "  (fc2): Linear(in_features=350, out_features=43, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % 2 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(BATCH_SIZE * LOG_INTERVAL),loss.data.item()))\n",
    "    print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 28 but got size 27 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_961491/3885531086.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_961491/707968878.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_961491/4280954265.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, normalize, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp_conv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nearest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUp_conv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 28 but got size 27 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e019fd396ec95f049220eceb1ef17507a867cb3a5a0d714b39db56f962322af5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
