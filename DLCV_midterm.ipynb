{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Midterm project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision.io import read_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nclasses):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm2d(100)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm2d(150)\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.bn3 = nn.BatchNorm2d(250)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(250*2*2, 350)\n",
    "        self.fc2 = nn.Linear(350, nclasses)\n",
    "\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "            )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 4 * 4, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "   \n",
    "        # Initialize the weights/bias with identity transformation\n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 4 * 4)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # transform the input\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # Perform forward pass\n",
    "        x = self.bn1(F.max_pool2d(F.leaky_relu(self.conv1(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn2(F.max_pool2d(F.leaky_relu(self.conv2(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.bn3(F.max_pool2d(F.leaky_relu(self.conv3(x)),2))\n",
    "        x = self.conv_drop(x)\n",
    "        x = x.view(-1, 250*2*2)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "class FMnet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        img_ch=1,\n",
    "        output_ch=1,\n",
    "        channels=[16, 32, 64, 128, 200],\n",
    "        device=['cuda' if torch.cuda.is_available() else 'cpu'][0],\n",
    "        kernel=3,\n",
    "        shape=(256, 256),\n",
    "        n_upsample=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_upsample = n_upsample\n",
    "        self.image_shape = shape\n",
    "        self.device = device\n",
    "\n",
    "        self.Conv = nn.Sequential()\n",
    "        self.Conv.add_module(\n",
    "            \"conv0\",\n",
    "            convblock(ch_in=img_ch, ch_out=channels[0], kernel_sz=kernel, block=0),\n",
    "        )\n",
    "        for k in range(1, len(channels)):\n",
    "            self.Conv.add_module(\n",
    "                f\"conv{k}\",\n",
    "                convblock(\n",
    "                    ch_in=channels[k - 1], ch_out=channels[k], kernel_sz=kernel, block=k\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.Up_conv = nn.Sequential()\n",
    "        for k in range(n_upsample):\n",
    "            self.Up_conv.add_module(\n",
    "                f\"upconv{k}\",\n",
    "                convblock(\n",
    "                    ch_in=channels[-1 - k] + channels[-2 - k],\n",
    "                    ch_out=channels[-2 - k],\n",
    "                    kernel_sz=kernel,\n",
    "                ),\n",
    "            )\n",
    "\n",
    "        self.Conv2_1x1 = nn.Sequential()\n",
    "        for j in range(3):\n",
    "            self.Conv2_1x1.add_module(\n",
    "                f\"conv{j}\",\n",
    "                nn.Conv2d(channels[-2 - k], output_ch, kernel_size=1, padding=0),\n",
    "            )\n",
    "\n",
    "    def forward(self, x, normalize=False, verbose=False):\n",
    "        # encoding path\n",
    "        xout = []\n",
    "        x = self.Conv[0](x)\n",
    "        xout.append(x)\n",
    "        for k in range(1, len(self.Conv)):\n",
    "            x = F.max_pool2d(x, kernel_size=3, stride=2, padding=1)\n",
    "            x = self.Conv[k](x)\n",
    "            xout.append(x)\n",
    "\n",
    "        for k in range(len(self.Up_conv)):\n",
    "            x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
    "            x = self.Up_conv[k](torch.cat((x, xout[-2 - k]), axis=1))\n",
    "\n",
    "        mask = self.Conv2_1x1[0](x)\n",
    "        mask_edges = self.Conv2_1x1[1](x)\n",
    "        mask_dist_to_boundary = self.Conv2_1x1[2](x)\n",
    "\n",
    "        return mask, mask_edges, mask_dist_to_boundary\n",
    "\n",
    "\n",
    "# Create a gaussian wavelet of a set bin size\n",
    "def gaussian_wavelet(bin_size, sigma):\n",
    "    x = np.arange(-bin_size // 2, bin_size // 2 + 1)\n",
    "    gaussian = np.exp(-(x ** 2) / (2 * sigma ** 2))\n",
    "    return gaussian / gaussian.sum()\n",
    "\n",
    "\n",
    "class convblock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out, kernel_sz, block=-1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential()\n",
    "        self.block = block\n",
    "        if self.block != 0:\n",
    "            self.conv.add_module(\"conv_0\", batchconv(ch_in, ch_out, kernel_sz))\n",
    "        else:\n",
    "            self.conv.add_module(\"conv_0\", batchconv0(ch_in, ch_out, kernel_sz))\n",
    "        self.conv.add_module(\"conv_1\", batchconv(ch_out, ch_out, kernel_sz))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv[1](self.conv[0](x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def batchconv0(ch_in, ch_out, kernel_sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.Conv2d(ch_in, ch_out, kernel_sz, padding=kernel_sz // 2, bias=False),\n",
    "    )\n",
    "\n",
    "\n",
    "def batchconv(ch_in, ch_out, sz):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(ch_in, eps=1e-5, momentum=0.1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(ch_in, ch_out, sz, padding=sz // 2, bias=False),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix test data targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 35288\n",
      "Number of validation samples = 3921\n"
     ]
    }
   ],
   "source": [
    "# Define path of training data\n",
    "transform = transforms.Compose([\n",
    "    # you can add other transformations in this list\n",
    "    #transforms.Grayscale(num_output_channels=1),\n",
    "    #transforms.Resize([212, 256]),\n",
    "    #transforms.ToTensor()\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "train_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Training_Images/GTSRB/Final_Training/Images' \n",
    "train_data = torchvision.datasets.ImageFolder(root = train_data_path, transform=transform)\n",
    "\n",
    "test_data_path = '/home/stringlab/Desktop/DLCV_midterm_project/GTSRB_Final_Test_Images/GTSRB'\n",
    "test_data = torchvision.datasets.ImageFolder(root = test_data_path, transform=transform)\n",
    "\n",
    "# Divide data into training and validation \n",
    "ratio = 0.9\n",
    "n_train_examples = int(len(train_data) * ratio)\n",
    "n_val_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, val_data = data.random_split(train_data, [n_train_examples, n_val_examples])\n",
    "print(f\"Number of training samples = {len(train_data)}\")\n",
    "print(f\"Number of validation samples = {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_classes = len(train_data.dataset.classes)\n",
    "train_hist = [0]*num_train_classes\n",
    "for i in train_data.indices:\n",
    "    tar = train_data.dataset.targets[i]\n",
    "    train_hist[tar] += 1\n",
    "\n",
    "num_val_classes = len(val_data.dataset.classes)\n",
    "val_hist = [0]*num_val_classes\n",
    "for i in val_data.indices:\n",
    "    tar = val_data.dataset.targets[i]\n",
    "    val_hist[tar] += 1\n",
    "\n",
    "num_test_classes = len(np.unique(test_data.targets))\n",
    "test_hist = [0]*num_test_classes\n",
    "for i, t in enumerate(test_data.targets):\n",
    "    test_hist[t] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '# of examples')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(num_train_classes), train_hist, label=\"train\")\n",
    "plt.bar(range(num_val_classes), val_hist, label=\"val\")\n",
    "#plt.bar(range(num_test_classes), test_hist, label=\"test\")\n",
    "legend = plt.legend(loc='upper right', shadow=True)\n",
    "plt.title(\"Distribution Plot\")\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"# of examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for training and validation\n",
    "BATCH_SIZE = 100\n",
    "LOG_INTERVAL = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = data.DataLoader(train_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "val_loader = data.DataLoader(val_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "test_loader = data.DataLoader(test_data, shuffle=True, batch_size = BATCH_SIZE)\n",
    "\n",
    "# Neural Network and Optimizer\n",
    "model = Net(num_train_classes)#FMnet()\n",
    "model = model.to(device);\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    training_loss = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data, target = data.to(device), target.to(device)   \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        max_index = output.max(dim = 1)[1]\n",
    "        correct += (max_index == target).sum()\n",
    "        training_loss += loss\n",
    "        if batch_idx % 2 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss per example: {:.6f}\\tLoss: {:.6f}'.format(\n",
    "                        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader), loss.data.item()/(BATCH_SIZE * LOG_INTERVAL),loss.data.item()))\n",
    "    print('\\nTraining set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                training_loss / len(train_loader.dataset), correct, len(train_loader.dataset),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        with torch.no_grad():\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(np.around(validation_loss,2))\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35288 (0%)]\tLoss per example: 0.001129\tLoss: 1.128941\n",
      "Train Epoch: 1 [200/35288 (1%)]\tLoss per example: 0.001219\tLoss: 1.218601\n",
      "Train Epoch: 1 [400/35288 (1%)]\tLoss per example: 0.001094\tLoss: 1.094437\n",
      "Train Epoch: 1 [600/35288 (2%)]\tLoss per example: 0.001268\tLoss: 1.267845\n",
      "Train Epoch: 1 [800/35288 (2%)]\tLoss per example: 0.001033\tLoss: 1.032981\n",
      "Train Epoch: 1 [1000/35288 (3%)]\tLoss per example: 0.001006\tLoss: 1.006065\n",
      "Train Epoch: 1 [1200/35288 (3%)]\tLoss per example: 0.000979\tLoss: 0.979281\n",
      "Train Epoch: 1 [1400/35288 (4%)]\tLoss per example: 0.001027\tLoss: 1.027071\n",
      "Train Epoch: 1 [1600/35288 (5%)]\tLoss per example: 0.000974\tLoss: 0.973763\n",
      "Train Epoch: 1 [1800/35288 (5%)]\tLoss per example: 0.000960\tLoss: 0.960280\n",
      "Train Epoch: 1 [2000/35288 (6%)]\tLoss per example: 0.000989\tLoss: 0.988942\n",
      "Train Epoch: 1 [2200/35288 (6%)]\tLoss per example: 0.000879\tLoss: 0.879004\n",
      "Train Epoch: 1 [2400/35288 (7%)]\tLoss per example: 0.001095\tLoss: 1.095318\n",
      "Train Epoch: 1 [2600/35288 (7%)]\tLoss per example: 0.000981\tLoss: 0.980697\n",
      "Train Epoch: 1 [2800/35288 (8%)]\tLoss per example: 0.000881\tLoss: 0.880578\n",
      "Train Epoch: 1 [3000/35288 (8%)]\tLoss per example: 0.000817\tLoss: 0.817441\n",
      "Train Epoch: 1 [3200/35288 (9%)]\tLoss per example: 0.000836\tLoss: 0.836373\n",
      "Train Epoch: 1 [3400/35288 (10%)]\tLoss per example: 0.000860\tLoss: 0.860374\n",
      "Train Epoch: 1 [3600/35288 (10%)]\tLoss per example: 0.000639\tLoss: 0.638619\n",
      "Train Epoch: 1 [3800/35288 (11%)]\tLoss per example: 0.000739\tLoss: 0.738789\n",
      "Train Epoch: 1 [4000/35288 (11%)]\tLoss per example: 0.000695\tLoss: 0.695369\n",
      "Train Epoch: 1 [4200/35288 (12%)]\tLoss per example: 0.000746\tLoss: 0.745954\n",
      "Train Epoch: 1 [4400/35288 (12%)]\tLoss per example: 0.000657\tLoss: 0.657173\n",
      "Train Epoch: 1 [4600/35288 (13%)]\tLoss per example: 0.000702\tLoss: 0.701689\n",
      "Train Epoch: 1 [4800/35288 (14%)]\tLoss per example: 0.000597\tLoss: 0.597421\n",
      "Train Epoch: 1 [5000/35288 (14%)]\tLoss per example: 0.000535\tLoss: 0.535027\n",
      "Train Epoch: 1 [5200/35288 (15%)]\tLoss per example: 0.000643\tLoss: 0.643226\n",
      "Train Epoch: 1 [5400/35288 (15%)]\tLoss per example: 0.000567\tLoss: 0.567001\n",
      "Train Epoch: 1 [5600/35288 (16%)]\tLoss per example: 0.000520\tLoss: 0.520099\n",
      "Train Epoch: 1 [5800/35288 (16%)]\tLoss per example: 0.000633\tLoss: 0.633285\n",
      "Train Epoch: 1 [6000/35288 (17%)]\tLoss per example: 0.000804\tLoss: 0.803643\n",
      "Train Epoch: 1 [6200/35288 (18%)]\tLoss per example: 0.000544\tLoss: 0.543551\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 50):\n",
    "    train(epoch)\n",
    "    validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e019fd396ec95f049220eceb1ef17507a867cb3a5a0d714b39db56f962322af5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
